# Guard.IAn - DetecÃ§Ã£o de ViolÃªncia em VÃ­deos

## ğŸ“– DescriÃ§Ã£o

O projeto Guard.IAn Ã© um sistema de inteligÃªncia artificial para detecÃ§Ã£o de violÃªncia em vÃ­deos. Utilizando uma Rede Neural Convolucional (CNN) baseada no modelo prÃ©-treinado VGG-16, o sistema analisa frames de vÃ­deo para classificar cenas como "Violentas" ou "NÃ£o Violentas".

O objetivo Ã© fornecer uma ferramenta que possa ser integrada a sistemas de monitoramento para identificar comportamentos agressivos de forma automÃ¡tica.

## ğŸ“‚ Estrutura do Projeto

Ao baixar este projeto, vocÃª terÃ¡ a seguinte estrutura de pastas:
```
GuardIAn/
|
â”œâ”€â”€ data/                 # Pasta principal para os vÃ­deos
|   â”œâ”€â”€ Violence/         # ARRASTE SEUS VÃDEOS DE VIOLÃŠNCIA AQUI
|   â””â”€â”€ NonViolence/      # ARRASTE SEUS VÃDEOS NORMAIS AQUI
|
â”œâ”€â”€ GuardIAn_FINAL.ipynb  # Notebook com todo o cÃ³digo
|
â””â”€â”€ README.md             # Este arquivo
```

## ğŸš€ Como Executar

1.  **Clone ou baixe o repositÃ³rio.**

2.  **Adicione os vÃ­deos:**
    - Baixe os vÃ­deos que deseja usar para o treinamento. (Se tiver um link pÃºblico para o dataset, coloque aqui).
    - Arraste os arquivos de vÃ­deo para dentro das pastas `data/Violence` e `data/NonViolence` que jÃ¡ existem no projeto.

3.  **Instale as bibliotecas:**
    ```bash
    pip install tensorflow opencv-python numpy matplotlib
    ```

4.  **Execute o Notebook:**
    Abra e rode o `GuardIAn_FINAL.ipynb`. O cÃ³digo irÃ¡ ler os vÃ­deos das pastas, treinar o modelo e salvÃ¡-lo automaticamente em uma nova pasta chamada `models`.
